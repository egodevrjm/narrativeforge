{"ast":null,"code":"/**\n * Service for handling interactions with Google's Gemini 2.5 Flash API\n */\nclass GeminiService {\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    this.baseUrl = 'https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent';\n    this.history = [];\n    this.characterProfile = null;\n    this.scenarioDetails = null;\n  }\n\n  /**\n   * Initialize the service with character and scenario information\n   * @param {Object} characterProfile - The detailed character profile\n   * @param {Object} scenarioDetails - The scenario setup details\n   */\n  initialize(characterProfile, scenarioDetails) {\n    this.characterProfile = characterProfile;\n    this.scenarioDetails = scenarioDetails;\n    this.history = [];\n\n    // Create system message that sets up the context\n    const systemContext = this._createSystemContext();\n    this.history.push({\n      role: 'system',\n      content: systemContext\n    });\n  }\n\n  /**\n   * Generate a generic response from Gemini based on a prompt\n   * @param {string} prompt - The prompt to send to Gemini\n   * @returns {Promise<string>} - The AI generated response\n   */\n  async generateGeneric(prompt) {\n    try {\n      var _data$candidates$, _data$candidates$$con, _data$candidates$$con2;\n      // Make API request to Gemini\n      const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n          contents: [{\n            role: 'user',\n            parts: [{\n              text: prompt\n            }]\n          }],\n          generationConfig: {\n            temperature: 0.7,\n            topK: 40,\n            topP: 0.95,\n            maxOutputTokens: 1000\n          }\n        })\n      });\n      const data = await response.json();\n\n      // Extract the model's response\n      if (data.candidates && ((_data$candidates$ = data.candidates[0]) === null || _data$candidates$ === void 0 ? void 0 : (_data$candidates$$con = _data$candidates$.content) === null || _data$candidates$$con === void 0 ? void 0 : (_data$candidates$$con2 = _data$candidates$$con.parts) === null || _data$candidates$$con2 === void 0 ? void 0 : _data$candidates$$con2.length) > 0) {\n        return data.candidates[0].content.parts[0].text;\n      } else {\n        throw new Error('Invalid response format from Gemini API');\n      }\n    } catch (error) {\n      console.error('Error calling Gemini API:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Generate a response from Gemini based on user input and context\n   * @param {string} userMessage - The user's message content\n   * @param {string} messageType - Type of message (dialogue, action, thought)\n   * @returns {Promise<string>} - The AI generated response\n   */\n  async generateResponse(userMessage, messageType) {\n    try {\n      var _data$candidates$2, _data$candidates$2$co, _data$candidates$2$co2;\n      // Add user message to history\n      this.history.push({\n        role: 'user',\n        content: `[${messageType.toUpperCase()}] ${userMessage}`\n      });\n\n      // Prepare the context window for Gemini\n      const prompt = this._preparePrompt();\n\n      // Make API request to Gemini\n      const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n          contents: prompt,\n          generationConfig: {\n            temperature: 0.7,\n            topK: 40,\n            topP: 0.95,\n            maxOutputTokens: 800\n          },\n          safetySettings: [{\n            category: \"HARM_CATEGORY_HARASSMENT\",\n            threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n          }, {\n            category: \"HARM_CATEGORY_HATE_SPEECH\",\n            threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n          }, {\n            category: \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n            threshold: \"BLOCK_ONLY_HIGH\"\n          }, {\n            category: \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n            threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n          }]\n        })\n      });\n      const data = await response.json();\n\n      // Extract the model's response\n      if (data.candidates && ((_data$candidates$2 = data.candidates[0]) === null || _data$candidates$2 === void 0 ? void 0 : (_data$candidates$2$co = _data$candidates$2.content) === null || _data$candidates$2$co === void 0 ? void 0 : (_data$candidates$2$co2 = _data$candidates$2$co.parts) === null || _data$candidates$2$co2 === void 0 ? void 0 : _data$candidates$2$co2.length) > 0) {\n        const aiResponseText = data.candidates[0].content.parts[0].text;\n\n        // Add AI response to history\n        this.history.push({\n          role: 'assistant',\n          content: aiResponseText\n        });\n        return aiResponseText;\n      } else {\n        throw new Error('Invalid response format from Gemini API');\n      }\n    } catch (error) {\n      console.error('Error calling Gemini API:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Create the detailed system context from character and scenario\n   * @private\n   * @returns {string} - Formatted system context\n   */\n  _createSystemContext() {\n    const {\n      name,\n      age,\n      physicalDescription,\n      background,\n      personality\n    } = this.characterProfile;\n    const {\n      title,\n      setting,\n      initialSituation,\n      otherCharacters,\n      toneAndThemes\n    } = this.scenarioDetails;\n\n    // Create detailed system prompt\n    return `\nYou are roleplaying in a scenario titled \"${title}\".\n\n## My Character\nName: ${name || 'Unnamed'}\nAge: ${age || 'Unknown'}\nPhysical Description: ${physicalDescription || 'Not provided'}\nBackground: ${background || 'Not provided'}\nPersonality: ${personality || 'Not provided'}\n\n## Scenario Setting\nLocation: ${(setting === null || setting === void 0 ? void 0 : setting.location) || 'Unspecified'}\nTime: ${(setting === null || setting === void 0 ? void 0 : setting.time) || 'Unspecified'}\nAtmosphere: ${(setting === null || setting === void 0 ? void 0 : setting.atmosphere) || 'Unspecified'}\n\n## Initial Situation\n${initialSituation || 'No initial situation provided.'}\n\n## Other Characters\n${(otherCharacters === null || otherCharacters === void 0 ? void 0 : otherCharacters.map(char => `\n- ${char.name} (${char.role}): ${char.description}\n  Relationship to protagonist: ${char.relationship}\n`).join('')) || 'No other characters specified.'}\n\n## Tone and Themes\n${toneAndThemes || 'No specific tone or themes specified.'}\n\n## Roleplay Instructions:\n1. You are roleplaying as the characters in this scenario EXCEPT the protagonist.\n2. Stay in character at all times and maintain a realistic, consistent tone.\n3. Respond to the protagonist's actions, dialogue, and thoughts appropriately.\n4. Ensure your responses reflect the emotional atmosphere of the scene.\n5. When the protagonist communicates, they may mark their message as [DIALOGUE], [ACTION], or [THOUGHT].\n6. Format your responses to clearly indicate dialogue, actions, and narrative elements.\n7. Help develop the story in the direction indicated by the protagonist's choices.\n8. Keep responses rich and immersive, but reasonably concise (2-5 paragraphs).\n9. Be creative, emotionally resonant, and authentic to the established characters and world.\n10. Never break character by discussing the nature of the roleplay itself.\n`;\n  }\n\n  /**\n   * Prepare the prompt with recent conversation history\n   * @private\n   * @returns {Array} - Formatted contents for Gemini API\n   */\n  _preparePrompt() {\n    // Keep a reasonable context window (system message + last 10 exchanges)\n    const recentHistory = [this.history[0],\n    // Always include system message\n    ...this.history.slice(Math.max(1, this.history.length - 20)) // Last 20 messages or fewer\n    ];\n\n    // Format for Gemini API\n    return recentHistory.map(msg => ({\n      role: msg.role,\n      parts: [{\n        text: msg.content\n      }]\n    }));\n  }\n\n  /**\n   * Save the current chat history\n   * @returns {Array} - The current chat history\n   */\n  exportChatHistory() {\n    return [...this.history];\n  }\n\n  /**\n   * Import an existing chat history\n   * @param {Array} history - Previous chat history\n   */\n  importChatHistory(history) {\n    this.history = [...history];\n  }\n}\nexport default GeminiService;","map":{"version":3,"names":["GeminiService","constructor","apiKey","baseUrl","history","characterProfile","scenarioDetails","initialize","systemContext","_createSystemContext","push","role","content","generateGeneric","prompt","_data$candidates$","_data$candidates$$con","_data$candidates$$con2","response","fetch","method","headers","body","JSON","stringify","contents","parts","text","generationConfig","temperature","topK","topP","maxOutputTokens","data","json","candidates","length","Error","error","console","generateResponse","userMessage","messageType","_data$candidates$2","_data$candidates$2$co","_data$candidates$2$co2","toUpperCase","_preparePrompt","safetySettings","category","threshold","aiResponseText","name","age","physicalDescription","background","personality","title","setting","initialSituation","otherCharacters","toneAndThemes","location","time","atmosphere","map","char","description","relationship","join","recentHistory","slice","Math","max","msg","exportChatHistory","importChatHistory"],"sources":["/Users/ryanmorrison/Code/narrativeforge/src/services/geminiService.js"],"sourcesContent":["/**\n * Service for handling interactions with Google's Gemini 2.5 Flash API\n */\nclass GeminiService {\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    this.baseUrl = 'https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent';\n    this.history = [];\n    this.characterProfile = null;\n    this.scenarioDetails = null;\n  }\n\n  /**\n   * Initialize the service with character and scenario information\n   * @param {Object} characterProfile - The detailed character profile\n   * @param {Object} scenarioDetails - The scenario setup details\n   */\n  initialize(characterProfile, scenarioDetails) {\n    this.characterProfile = characterProfile;\n    this.scenarioDetails = scenarioDetails;\n    this.history = [];\n    \n    // Create system message that sets up the context\n    const systemContext = this._createSystemContext();\n    this.history.push({\n      role: 'system',\n      content: systemContext\n    });\n  }\n\n  /**\n   * Generate a generic response from Gemini based on a prompt\n   * @param {string} prompt - The prompt to send to Gemini\n   * @returns {Promise<string>} - The AI generated response\n   */\n  async generateGeneric(prompt) {\n    try {\n      // Make API request to Gemini\n      const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          contents: [{\n            role: 'user',\n            parts: [{ text: prompt }]\n          }],\n          generationConfig: {\n            temperature: 0.7,\n            topK: 40,\n            topP: 0.95,\n            maxOutputTokens: 1000,\n          }\n        })\n      });\n\n      const data = await response.json();\n      \n      // Extract the model's response\n      if (data.candidates && data.candidates[0]?.content?.parts?.length > 0) {\n        return data.candidates[0].content.parts[0].text;\n      } else {\n        throw new Error('Invalid response format from Gemini API');\n      }\n    } catch (error) {\n      console.error('Error calling Gemini API:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Generate a response from Gemini based on user input and context\n   * @param {string} userMessage - The user's message content\n   * @param {string} messageType - Type of message (dialogue, action, thought)\n   * @returns {Promise<string>} - The AI generated response\n   */\n  async generateResponse(userMessage, messageType) {\n    try {\n      // Add user message to history\n      this.history.push({\n        role: 'user',\n        content: `[${messageType.toUpperCase()}] ${userMessage}`\n      });\n\n      // Prepare the context window for Gemini\n      const prompt = this._preparePrompt();\n\n      // Make API request to Gemini\n      const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          contents: prompt,\n          generationConfig: {\n            temperature: 0.7,\n            topK: 40,\n            topP: 0.95,\n            maxOutputTokens: 800,\n          },\n          safetySettings: [\n            {\n              category: \"HARM_CATEGORY_HARASSMENT\",\n              threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n            },\n            {\n              category: \"HARM_CATEGORY_HATE_SPEECH\",\n              threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n            },\n            {\n              category: \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n              threshold: \"BLOCK_ONLY_HIGH\"\n            },\n            {\n              category: \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n              threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n            }\n          ]\n        })\n      });\n\n      const data = await response.json();\n      \n      // Extract the model's response\n      if (data.candidates && data.candidates[0]?.content?.parts?.length > 0) {\n        const aiResponseText = data.candidates[0].content.parts[0].text;\n        \n        // Add AI response to history\n        this.history.push({\n          role: 'assistant',\n          content: aiResponseText\n        });\n        \n        return aiResponseText;\n      } else {\n        throw new Error('Invalid response format from Gemini API');\n      }\n    } catch (error) {\n      console.error('Error calling Gemini API:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Create the detailed system context from character and scenario\n   * @private\n   * @returns {string} - Formatted system context\n   */\n  _createSystemContext() {\n    const { name, age, physicalDescription, background, personality } = this.characterProfile;\n    const { title, setting, initialSituation, otherCharacters, toneAndThemes } = this.scenarioDetails;\n\n    // Create detailed system prompt\n    return `\nYou are roleplaying in a scenario titled \"${title}\".\n\n## My Character\nName: ${name || 'Unnamed'}\nAge: ${age || 'Unknown'}\nPhysical Description: ${physicalDescription || 'Not provided'}\nBackground: ${background || 'Not provided'}\nPersonality: ${personality || 'Not provided'}\n\n## Scenario Setting\nLocation: ${setting?.location || 'Unspecified'}\nTime: ${setting?.time || 'Unspecified'}\nAtmosphere: ${setting?.atmosphere || 'Unspecified'}\n\n## Initial Situation\n${initialSituation || 'No initial situation provided.'}\n\n## Other Characters\n${otherCharacters?.map(char => `\n- ${char.name} (${char.role}): ${char.description}\n  Relationship to protagonist: ${char.relationship}\n`).join('') || 'No other characters specified.'}\n\n## Tone and Themes\n${toneAndThemes || 'No specific tone or themes specified.'}\n\n## Roleplay Instructions:\n1. You are roleplaying as the characters in this scenario EXCEPT the protagonist.\n2. Stay in character at all times and maintain a realistic, consistent tone.\n3. Respond to the protagonist's actions, dialogue, and thoughts appropriately.\n4. Ensure your responses reflect the emotional atmosphere of the scene.\n5. When the protagonist communicates, they may mark their message as [DIALOGUE], [ACTION], or [THOUGHT].\n6. Format your responses to clearly indicate dialogue, actions, and narrative elements.\n7. Help develop the story in the direction indicated by the protagonist's choices.\n8. Keep responses rich and immersive, but reasonably concise (2-5 paragraphs).\n9. Be creative, emotionally resonant, and authentic to the established characters and world.\n10. Never break character by discussing the nature of the roleplay itself.\n`;\n  }\n\n  /**\n   * Prepare the prompt with recent conversation history\n   * @private\n   * @returns {Array} - Formatted contents for Gemini API\n   */\n  _preparePrompt() {\n    // Keep a reasonable context window (system message + last 10 exchanges)\n    const recentHistory = [\n      this.history[0], // Always include system message\n      ...this.history.slice(Math.max(1, this.history.length - 20)) // Last 20 messages or fewer\n    ];\n    \n    // Format for Gemini API\n    return recentHistory.map(msg => ({\n      role: msg.role,\n      parts: [{ text: msg.content }]\n    }));\n  }\n\n  /**\n   * Save the current chat history\n   * @returns {Array} - The current chat history\n   */\n  exportChatHistory() {\n    return [...this.history];\n  }\n\n  /**\n   * Import an existing chat history\n   * @param {Array} history - Previous chat history\n   */\n  importChatHistory(history) {\n    this.history = [...history];\n  }\n}\n\nexport default GeminiService;"],"mappings":"AAAA;AACA;AACA;AACA,MAAMA,aAAa,CAAC;EAClBC,WAAWA,CAACC,MAAM,EAAE;IAClB,IAAI,CAACA,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACC,OAAO,GAAG,sFAAsF;IACrG,IAAI,CAACC,OAAO,GAAG,EAAE;IACjB,IAAI,CAACC,gBAAgB,GAAG,IAAI;IAC5B,IAAI,CAACC,eAAe,GAAG,IAAI;EAC7B;;EAEA;AACF;AACA;AACA;AACA;EACEC,UAAUA,CAACF,gBAAgB,EAAEC,eAAe,EAAE;IAC5C,IAAI,CAACD,gBAAgB,GAAGA,gBAAgB;IACxC,IAAI,CAACC,eAAe,GAAGA,eAAe;IACtC,IAAI,CAACF,OAAO,GAAG,EAAE;;IAEjB;IACA,MAAMI,aAAa,GAAG,IAAI,CAACC,oBAAoB,CAAC,CAAC;IACjD,IAAI,CAACL,OAAO,CAACM,IAAI,CAAC;MAChBC,IAAI,EAAE,QAAQ;MACdC,OAAO,EAAEJ;IACX,CAAC,CAAC;EACJ;;EAEA;AACF;AACA;AACA;AACA;EACE,MAAMK,eAAeA,CAACC,MAAM,EAAE;IAC5B,IAAI;MAAA,IAAAC,iBAAA,EAAAC,qBAAA,EAAAC,sBAAA;MACF;MACA,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAG,IAAI,CAAChB,OAAO,QAAQ,IAAI,CAACD,MAAM,EAAE,EAAE;QACjEkB,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UACP,cAAc,EAAE;QAClB,CAAC;QACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UACnBC,QAAQ,EAAE,CAAC;YACTd,IAAI,EAAE,MAAM;YACZe,KAAK,EAAE,CAAC;cAAEC,IAAI,EAAEb;YAAO,CAAC;UAC1B,CAAC,CAAC;UACFc,gBAAgB,EAAE;YAChBC,WAAW,EAAE,GAAG;YAChBC,IAAI,EAAE,EAAE;YACRC,IAAI,EAAE,IAAI;YACVC,eAAe,EAAE;UACnB;QACF,CAAC;MACH,CAAC,CAAC;MAEF,MAAMC,IAAI,GAAG,MAAMf,QAAQ,CAACgB,IAAI,CAAC,CAAC;;MAElC;MACA,IAAID,IAAI,CAACE,UAAU,IAAI,EAAApB,iBAAA,GAAAkB,IAAI,CAACE,UAAU,CAAC,CAAC,CAAC,cAAApB,iBAAA,wBAAAC,qBAAA,GAAlBD,iBAAA,CAAoBH,OAAO,cAAAI,qBAAA,wBAAAC,sBAAA,GAA3BD,qBAAA,CAA6BU,KAAK,cAAAT,sBAAA,uBAAlCA,sBAAA,CAAoCmB,MAAM,IAAG,CAAC,EAAE;QACrE,OAAOH,IAAI,CAACE,UAAU,CAAC,CAAC,CAAC,CAACvB,OAAO,CAACc,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI;MACjD,CAAC,MAAM;QACL,MAAM,IAAIU,KAAK,CAAC,yCAAyC,CAAC;MAC5D;IACF,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,2BAA2B,EAAEA,KAAK,CAAC;MACjD,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,MAAME,gBAAgBA,CAACC,WAAW,EAAEC,WAAW,EAAE;IAC/C,IAAI;MAAA,IAAAC,kBAAA,EAAAC,qBAAA,EAAAC,sBAAA;MACF;MACA,IAAI,CAACzC,OAAO,CAACM,IAAI,CAAC;QAChBC,IAAI,EAAE,MAAM;QACZC,OAAO,EAAE,IAAI8B,WAAW,CAACI,WAAW,CAAC,CAAC,KAAKL,WAAW;MACxD,CAAC,CAAC;;MAEF;MACA,MAAM3B,MAAM,GAAG,IAAI,CAACiC,cAAc,CAAC,CAAC;;MAEpC;MACA,MAAM7B,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAG,IAAI,CAAChB,OAAO,QAAQ,IAAI,CAACD,MAAM,EAAE,EAAE;QACjEkB,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UACP,cAAc,EAAE;QAClB,CAAC;QACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UACnBC,QAAQ,EAAEX,MAAM;UAChBc,gBAAgB,EAAE;YAChBC,WAAW,EAAE,GAAG;YAChBC,IAAI,EAAE,EAAE;YACRC,IAAI,EAAE,IAAI;YACVC,eAAe,EAAE;UACnB,CAAC;UACDgB,cAAc,EAAE,CACd;YACEC,QAAQ,EAAE,0BAA0B;YACpCC,SAAS,EAAE;UACb,CAAC,EACD;YACED,QAAQ,EAAE,2BAA2B;YACrCC,SAAS,EAAE;UACb,CAAC,EACD;YACED,QAAQ,EAAE,iCAAiC;YAC3CC,SAAS,EAAE;UACb,CAAC,EACD;YACED,QAAQ,EAAE,iCAAiC;YAC3CC,SAAS,EAAE;UACb,CAAC;QAEL,CAAC;MACH,CAAC,CAAC;MAEF,MAAMjB,IAAI,GAAG,MAAMf,QAAQ,CAACgB,IAAI,CAAC,CAAC;;MAElC;MACA,IAAID,IAAI,CAACE,UAAU,IAAI,EAAAQ,kBAAA,GAAAV,IAAI,CAACE,UAAU,CAAC,CAAC,CAAC,cAAAQ,kBAAA,wBAAAC,qBAAA,GAAlBD,kBAAA,CAAoB/B,OAAO,cAAAgC,qBAAA,wBAAAC,sBAAA,GAA3BD,qBAAA,CAA6BlB,KAAK,cAAAmB,sBAAA,uBAAlCA,sBAAA,CAAoCT,MAAM,IAAG,CAAC,EAAE;QACrE,MAAMe,cAAc,GAAGlB,IAAI,CAACE,UAAU,CAAC,CAAC,CAAC,CAACvB,OAAO,CAACc,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI;;QAE/D;QACA,IAAI,CAACvB,OAAO,CAACM,IAAI,CAAC;UAChBC,IAAI,EAAE,WAAW;UACjBC,OAAO,EAAEuC;QACX,CAAC,CAAC;QAEF,OAAOA,cAAc;MACvB,CAAC,MAAM;QACL,MAAM,IAAId,KAAK,CAAC,yCAAyC,CAAC;MAC5D;IACF,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,2BAA2B,EAAEA,KAAK,CAAC;MACjD,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;EACE7B,oBAAoBA,CAAA,EAAG;IACrB,MAAM;MAAE2C,IAAI;MAAEC,GAAG;MAAEC,mBAAmB;MAAEC,UAAU;MAAEC;IAAY,CAAC,GAAG,IAAI,CAACnD,gBAAgB;IACzF,MAAM;MAAEoD,KAAK;MAAEC,OAAO;MAAEC,gBAAgB;MAAEC,eAAe;MAAEC;IAAc,CAAC,GAAG,IAAI,CAACvD,eAAe;;IAEjG;IACA,OAAO;AACX,4CAA4CmD,KAAK;AACjD;AACA;AACA,QAAQL,IAAI,IAAI,SAAS;AACzB,OAAOC,GAAG,IAAI,SAAS;AACvB,wBAAwBC,mBAAmB,IAAI,cAAc;AAC7D,cAAcC,UAAU,IAAI,cAAc;AAC1C,eAAeC,WAAW,IAAI,cAAc;AAC5C;AACA;AACA,YAAY,CAAAE,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEI,QAAQ,KAAI,aAAa;AAC9C,QAAQ,CAAAJ,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEK,IAAI,KAAI,aAAa;AACtC,cAAc,CAAAL,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEM,UAAU,KAAI,aAAa;AAClD;AACA;AACA,EAAEL,gBAAgB,IAAI,gCAAgC;AACtD;AACA;AACA,EAAE,CAAAC,eAAe,aAAfA,eAAe,uBAAfA,eAAe,CAAEK,GAAG,CAACC,IAAI,IAAI;AAC/B,IAAIA,IAAI,CAACd,IAAI,KAAKc,IAAI,CAACvD,IAAI,MAAMuD,IAAI,CAACC,WAAW;AACjD,iCAAiCD,IAAI,CAACE,YAAY;AAClD,CAAC,CAAC,CAACC,IAAI,CAAC,EAAE,CAAC,KAAI,gCAAgC;AAC/C;AACA;AACA,EAAER,aAAa,IAAI,uCAAuC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;EACC;;EAEA;AACF;AACA;AACA;AACA;EACEd,cAAcA,CAAA,EAAG;IACf;IACA,MAAMuB,aAAa,GAAG,CACpB,IAAI,CAAClE,OAAO,CAAC,CAAC,CAAC;IAAE;IACjB,GAAG,IAAI,CAACA,OAAO,CAACmE,KAAK,CAACC,IAAI,CAACC,GAAG,CAAC,CAAC,EAAE,IAAI,CAACrE,OAAO,CAACgC,MAAM,GAAG,EAAE,CAAC,CAAC,CAAC;IAAA,CAC9D;;IAED;IACA,OAAOkC,aAAa,CAACL,GAAG,CAACS,GAAG,KAAK;MAC/B/D,IAAI,EAAE+D,GAAG,CAAC/D,IAAI;MACde,KAAK,EAAE,CAAC;QAAEC,IAAI,EAAE+C,GAAG,CAAC9D;MAAQ,CAAC;IAC/B,CAAC,CAAC,CAAC;EACL;;EAEA;AACF;AACA;AACA;EACE+D,iBAAiBA,CAAA,EAAG;IAClB,OAAO,CAAC,GAAG,IAAI,CAACvE,OAAO,CAAC;EAC1B;;EAEA;AACF;AACA;AACA;EACEwE,iBAAiBA,CAACxE,OAAO,EAAE;IACzB,IAAI,CAACA,OAAO,GAAG,CAAC,GAAGA,OAAO,CAAC;EAC7B;AACF;AAEA,eAAeJ,aAAa","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}