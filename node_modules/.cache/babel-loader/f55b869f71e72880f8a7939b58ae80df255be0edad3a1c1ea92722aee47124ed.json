{"ast":null,"code":"/**\n * Service for handling interactions with Google's Gemini AI API\n */\nclass GeminiService {\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    // Try using a more stable model instead of flash\n    this.baseUrl = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:generateContent';\n    this.history = [];\n    this.characterProfile = null;\n    this.scenarioDetails = null;\n  }\n\n  /**\n   * Initialize the service with character and scenario information\n   * @param {Object} characterProfile - The detailed character profile\n   * @param {Object} scenarioDetails - The scenario setup details\n   */\n  initialize(characterProfile, scenarioDetails) {\n    this.characterProfile = characterProfile;\n    this.scenarioDetails = scenarioDetails;\n    this.history = [];\n\n    // Create system message that sets up the context\n    const systemContext = this._createSystemContext();\n    this.history.push({\n      role: 'model',\n      parts: [{\n        text: systemContext\n      }]\n    });\n\n    // If there are roleplay instructions, add them as system context\n    if (scenarioDetails.roleplayInstructions) {\n      this.history.push({\n        role: 'model',\n        parts: [{\n          text: `Roleplay Instructions:\\n\\n${scenarioDetails.roleplayInstructions}`\n        }]\n      });\n    }\n  }\n\n  /**\n   * Update roleplay instructions\n   * @param {string} instructions - New roleplay instructions\n   */\n  updateInstructions(instructions) {\n    // Find any existing instruction message\n    const existingInstructionIndex = this.history.findIndex(msg => {\n      var _msg$parts$, _msg$parts$$text;\n      return msg.role === 'model' && ((_msg$parts$ = msg.parts[0]) === null || _msg$parts$ === void 0 ? void 0 : (_msg$parts$$text = _msg$parts$.text) === null || _msg$parts$$text === void 0 ? void 0 : _msg$parts$$text.includes('Roleplay Instructions:'));\n    });\n\n    // Create the instruction message\n    const instructionMessage = {\n      role: 'model',\n      parts: [{\n        text: `Roleplay Instructions:\\n\\n${instructions}`\n      }]\n    };\n    if (existingInstructionIndex !== -1) {\n      // Replace existing instructions\n      this.history[existingInstructionIndex] = instructionMessage;\n    } else {\n      // Add new instructions after the system context\n      this.history.splice(1, 0, instructionMessage);\n    }\n\n    // Add a reminder to follow the new instructions (not visible to user)\n    this.history.push({\n      role: 'model',\n      parts: [{\n        text: 'Remember to follow the updated roleplay instructions provided above, but do not explicitly mention them in your responses.'\n      }]\n    });\n  }\n\n  /**\n   * Generate a generic response from Gemini based on a prompt\n   * @param {string} prompt - The prompt to send to Gemini\n   * @returns {Promise<string>} - The AI generated response\n   */\n  async generateGeneric(prompt) {\n    try {\n      console.log('Sending request to Gemini API');\n      console.log('Using API URL:', this.baseUrl);\n      try {\n        var _data$candidates$, _data$candidates$$con, _data$candidates$$con2;\n        // Add retry logic with exponential backoff\n        let retries = 3;\n        let delay = 1000; // Start with 1 second delay\n        let success = false;\n        let data;\n        while (retries > 0 && !success) {\n          try {\n            const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {\n              method: 'POST',\n              headers: {\n                'Content-Type': 'application/json'\n              },\n              body: JSON.stringify({\n                contents: [{\n                  role: 'user',\n                  parts: [{\n                    text: prompt\n                  }]\n                }],\n                generationConfig: {\n                  temperature: 0.7,\n                  topK: 40,\n                  topP: 0.95,\n                  maxOutputTokens: 1000\n                }\n              })\n            });\n\n            // Check HTTP status before trying to parse JSON\n            if (!response.ok) {\n              const errorText = await response.text();\n              console.error('API error response:', errorText);\n              throw new Error(`API error: ${response.status} - ${errorText || 'Unknown error'}`);\n            }\n            data = await response.json();\n            console.log('API response structure:', JSON.stringify(data, null, 2).substring(0, 500) + '...');\n            success = true;\n          } catch (err) {\n            console.error(`Attempt ${4 - retries} failed:`, err);\n            retries--;\n            if (retries > 0) {\n              console.log(`Retrying in ${delay}ms...`);\n              await new Promise(resolve => setTimeout(resolve, delay));\n              delay *= 2; // Exponential backoff\n            } else {\n              throw err; // Re-throw the last error if all retries failed\n            }\n          }\n        }\n\n        // Extract the model's response\n        if (data.candidates && ((_data$candidates$ = data.candidates[0]) === null || _data$candidates$ === void 0 ? void 0 : (_data$candidates$$con = _data$candidates$.content) === null || _data$candidates$$con === void 0 ? void 0 : (_data$candidates$$con2 = _data$candidates$$con.parts) === null || _data$candidates$$con2 === void 0 ? void 0 : _data$candidates$$con2.length) > 0) {\n          return data.candidates[0].content.parts[0].text;\n        } else {\n          console.error('Unexpected API response structure:', data);\n          throw new Error('Invalid response format from Gemini API');\n        }\n      } catch (fetchError) {\n        console.error('Fetch error:', fetchError);\n        throw fetchError;\n      }\n    } catch (error) {\n      console.error('Error calling Gemini API:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Generate a response from Gemini based on user input and context\n   * @param {string} userMessage - The user's message content\n   * @param {string} messageType - Type of message (dialogue, action, thought)\n   * @returns {Promise<string>} - The AI generated response\n   */\n  async generateResponse(userMessage, messageType) {\n    try {\n      // Add user message to history\n      this.history.push({\n        role: 'user',\n        parts: [{\n          text: `[${messageType.toUpperCase()}] ${userMessage}`\n        }]\n      });\n\n      // Prepare the context window for Gemini\n      const contents = [...this.history];\n      console.log('Sending roleplay request to Gemini API');\n      console.log('Using model URL:', this.baseUrl);\n      try {\n        var _data$candidates$2, _data$candidates$2$co, _data$candidates$2$co2;\n        // Add retry logic with exponential backoff\n        let retries = 3;\n        let delay = 1000; // Start with 1 second delay\n        let success = false;\n        let data;\n        while (retries > 0 && !success) {\n          try {\n            const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {\n              method: 'POST',\n              headers: {\n                'Content-Type': 'application/json'\n              },\n              body: JSON.stringify({\n                contents: contents,\n                generationConfig: {\n                  temperature: 0.7,\n                  topK: 40,\n                  topP: 0.95,\n                  maxOutputTokens: 800\n                },\n                safetySettings: [{\n                  category: \"HARM_CATEGORY_HARASSMENT\",\n                  threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n                }, {\n                  category: \"HARM_CATEGORY_HATE_SPEECH\",\n                  threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n                }, {\n                  category: \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n                  threshold: \"BLOCK_ONLY_HIGH\"\n                }, {\n                  category: \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n                  threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n                }]\n              })\n            });\n\n            // Check HTTP status before trying to parse JSON\n            if (!response.ok) {\n              const errorText = await response.text();\n              console.error('API error response for roleplay:', errorText);\n              throw new Error(`API error in roleplay: ${response.status} - ${errorText || 'Unknown error'}`);\n            }\n            data = await response.json();\n            success = true;\n          } catch (err) {\n            console.error(`Attempt ${4 - retries} failed:`, err);\n            retries--;\n            if (retries > 0) {\n              console.log(`Retrying in ${delay}ms...`);\n              await new Promise(resolve => setTimeout(resolve, delay));\n              delay *= 2; // Exponential backoff\n            } else {\n              throw err; // Re-throw the last error if all retries failed\n            }\n          }\n        }\n\n        // Extract the model's response\n        if (data.candidates && ((_data$candidates$2 = data.candidates[0]) === null || _data$candidates$2 === void 0 ? void 0 : (_data$candidates$2$co = _data$candidates$2.content) === null || _data$candidates$2$co === void 0 ? void 0 : (_data$candidates$2$co2 = _data$candidates$2$co.parts) === null || _data$candidates$2$co2 === void 0 ? void 0 : _data$candidates$2$co2.length) > 0) {\n          const aiResponseText = data.candidates[0].content.parts[0].text;\n\n          // Add AI response to history\n          this.history.push({\n            role: 'model',\n            parts: [{\n              text: aiResponseText\n            }]\n          });\n          return aiResponseText;\n        } else {\n          console.error('Unexpected roleplay API response structure:', data);\n          throw new Error('Invalid response format from Gemini API in roleplay');\n        }\n      } catch (fetchError) {\n        console.error('Fetch error in roleplay:', fetchError);\n        throw fetchError;\n      }\n    } catch (error) {\n      console.error('Error calling Gemini API:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Create the detailed system context from character and scenario\n   * @private\n   * @returns {string} - Formatted system context\n   */\n  _createSystemContext() {\n    const {\n      name,\n      age,\n      physicalDescription,\n      background,\n      personality\n    } = this.characterProfile;\n    const {\n      title,\n      setting,\n      initialSituation,\n      otherCharacters,\n      toneAndThemes\n    } = this.scenarioDetails;\n\n    // Create detailed system prompt\n    return `\nYou are roleplaying in a scenario titled \"${title}\".\n\n## My Character\nName: ${name || 'Unnamed'}\nAge: ${age || 'Unknown'}\nPhysical Description: ${physicalDescription || 'Not provided'}\nBackground: ${background || 'Not provided'}\nPersonality: ${personality || 'Not provided'}\n\n## Scenario Setting\nLocation: ${(setting === null || setting === void 0 ? void 0 : setting.location) || 'Unspecified'}\nTime: ${(setting === null || setting === void 0 ? void 0 : setting.time) || 'Unspecified'}\nAtmosphere: ${(setting === null || setting === void 0 ? void 0 : setting.atmosphere) || 'Unspecified'}\n\n## Initial Situation\n${initialSituation || 'No initial situation provided.'}\n\n## Other Characters\n${(otherCharacters === null || otherCharacters === void 0 ? void 0 : otherCharacters.map(char => `\n- ${char.name} (${char.role}): ${char.description}\n  Relationship to protagonist: ${char.relationship}\n`).join('')) || 'No other characters specified.'}\n\n## Tone and Themes\n${toneAndThemes || 'No specific tone or themes specified.'}\n\n## Roleplay Instructions:\n1. You are roleplaying as the characters in this scenario EXCEPT the protagonist.\n2. Stay in character at all times and maintain a realistic, consistent tone.\n3. Respond to the protagonist's actions, dialogue, and thoughts appropriately.\n4. Ensure your responses reflect the emotional atmosphere of the scene.\n5. When the protagonist communicates, they may mark their message as [DIALOGUE], [ACTION], or [THOUGHT].\n6. Format your responses to clearly indicate dialogue, actions, and narrative elements.\n7. Help develop the story in the direction indicated by the protagonist's choices.\n8. Keep responses rich and immersive, but reasonably concise (2-5 paragraphs).\n9. Be creative, emotionally resonant, and authentic to the established characters and world.\n10. Never break character by discussing the nature of the roleplay itself.\n`;\n  }\n\n  /**\n   * Save the current chat history\n   * @returns {Array} - The current chat history\n   */\n  exportChatHistory() {\n    return [...this.history];\n  }\n\n  /**\n   * Import an existing chat history\n   * @param {Array} history - Previous chat history\n   */\n  importChatHistory(history) {\n    this.history = [...history];\n  }\n}\nexport default GeminiService;","map":{"version":3,"names":["GeminiService","constructor","apiKey","baseUrl","history","characterProfile","scenarioDetails","initialize","systemContext","_createSystemContext","push","role","parts","text","roleplayInstructions","updateInstructions","instructions","existingInstructionIndex","findIndex","msg","_msg$parts$","_msg$parts$$text","includes","instructionMessage","splice","generateGeneric","prompt","console","log","_data$candidates$","_data$candidates$$con","_data$candidates$$con2","retries","delay","success","data","response","fetch","method","headers","body","JSON","stringify","contents","generationConfig","temperature","topK","topP","maxOutputTokens","ok","errorText","error","Error","status","json","substring","err","Promise","resolve","setTimeout","candidates","content","length","fetchError","generateResponse","userMessage","messageType","toUpperCase","_data$candidates$2","_data$candidates$2$co","_data$candidates$2$co2","safetySettings","category","threshold","aiResponseText","name","age","physicalDescription","background","personality","title","setting","initialSituation","otherCharacters","toneAndThemes","location","time","atmosphere","map","char","description","relationship","join","exportChatHistory","importChatHistory"],"sources":["/Users/ryanmorrison/Code/narrativeforge/src/services/geminiService.js"],"sourcesContent":["/**\n * Service for handling interactions with Google's Gemini AI API\n */\nclass GeminiService {\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    // Try using a more stable model instead of flash\n    this.baseUrl = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:generateContent';\n    this.history = [];\n    this.characterProfile = null;\n    this.scenarioDetails = null;\n  }\n\n  /**\n   * Initialize the service with character and scenario information\n   * @param {Object} characterProfile - The detailed character profile\n   * @param {Object} scenarioDetails - The scenario setup details\n   */\n  initialize(characterProfile, scenarioDetails) {\n    this.characterProfile = characterProfile;\n    this.scenarioDetails = scenarioDetails;\n    this.history = [];\n    \n    // Create system message that sets up the context\n    const systemContext = this._createSystemContext();\n    this.history.push({\n      role: 'model',\n      parts: [{ text: systemContext }]\n    });\n    \n    // If there are roleplay instructions, add them as system context\n    if (scenarioDetails.roleplayInstructions) {\n      this.history.push({\n        role: 'model',\n        parts: [{ text: `Roleplay Instructions:\\n\\n${scenarioDetails.roleplayInstructions}` }]\n      });\n    }\n  }\n\n  /**\n   * Update roleplay instructions\n   * @param {string} instructions - New roleplay instructions\n   */\n  updateInstructions(instructions) {\n    // Find any existing instruction message\n    const existingInstructionIndex = this.history.findIndex(msg => \n      msg.role === 'model' && \n      msg.parts[0]?.text?.includes('Roleplay Instructions:')\n    );\n    \n    // Create the instruction message\n    const instructionMessage = {\n      role: 'model',\n      parts: [{ text: `Roleplay Instructions:\\n\\n${instructions}` }]\n    };\n    \n    if (existingInstructionIndex !== -1) {\n      // Replace existing instructions\n      this.history[existingInstructionIndex] = instructionMessage;\n    } else {\n      // Add new instructions after the system context\n      this.history.splice(1, 0, instructionMessage);\n    }\n    \n    // Add a reminder to follow the new instructions (not visible to user)\n    this.history.push({\n      role: 'model',\n      parts: [{ text: 'Remember to follow the updated roleplay instructions provided above, but do not explicitly mention them in your responses.' }]\n    });\n  }\n\n  /**\n   * Generate a generic response from Gemini based on a prompt\n   * @param {string} prompt - The prompt to send to Gemini\n   * @returns {Promise<string>} - The AI generated response\n   */\n  async generateGeneric(prompt) {\n    try {\n      console.log('Sending request to Gemini API');\n      console.log('Using API URL:', this.baseUrl);\n      \n      try {\n        // Add retry logic with exponential backoff\n        let retries = 3;\n        let delay = 1000; // Start with 1 second delay\n        let success = false;\n        let data;\n        \n        while (retries > 0 && !success) {\n          try {\n            const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {\n              method: 'POST',\n              headers: {\n                'Content-Type': 'application/json',\n              },\n              body: JSON.stringify({\n                contents: [{\n                  role: 'user',\n                  parts: [{ text: prompt }]\n                }],\n                generationConfig: {\n                  temperature: 0.7,\n                  topK: 40,\n                  topP: 0.95,\n                  maxOutputTokens: 1000,\n                }\n              })\n            });\n    \n            // Check HTTP status before trying to parse JSON\n            if (!response.ok) {\n              const errorText = await response.text();\n              console.error('API error response:', errorText);\n              throw new Error(`API error: ${response.status} - ${errorText || 'Unknown error'}`);\n            }\n    \n            data = await response.json();\n            console.log('API response structure:', JSON.stringify(data, null, 2).substring(0, 500) + '...');\n            success = true;\n          } catch (err) {\n            console.error(`Attempt ${4-retries} failed:`, err);\n            retries--;\n            \n            if (retries > 0) {\n              console.log(`Retrying in ${delay}ms...`);\n              await new Promise(resolve => setTimeout(resolve, delay));\n              delay *= 2; // Exponential backoff\n            } else {\n              throw err; // Re-throw the last error if all retries failed\n            }\n          }\n        }\n        \n        // Extract the model's response\n        if (data.candidates && data.candidates[0]?.content?.parts?.length > 0) {\n          return data.candidates[0].content.parts[0].text;\n        } else {\n          console.error('Unexpected API response structure:', data);\n          throw new Error('Invalid response format from Gemini API');\n        }\n      } catch (fetchError) {\n        console.error('Fetch error:', fetchError);\n        throw fetchError;\n      }\n    } catch (error) {\n      console.error('Error calling Gemini API:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Generate a response from Gemini based on user input and context\n   * @param {string} userMessage - The user's message content\n   * @param {string} messageType - Type of message (dialogue, action, thought)\n   * @returns {Promise<string>} - The AI generated response\n   */\n  async generateResponse(userMessage, messageType) {\n    try {\n      // Add user message to history\n      this.history.push({\n        role: 'user',\n        parts: [{ text: `[${messageType.toUpperCase()}] ${userMessage}` }]\n      });\n\n      // Prepare the context window for Gemini\n      const contents = [...this.history];\n\n      console.log('Sending roleplay request to Gemini API');\n      console.log('Using model URL:', this.baseUrl);\n      \n      try {\n        // Add retry logic with exponential backoff\n        let retries = 3;\n        let delay = 1000; // Start with 1 second delay\n        let success = false;\n        let data;\n\n        while (retries > 0 && !success) {\n          try {\n            const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {\n              method: 'POST',\n              headers: {\n                'Content-Type': 'application/json',\n              },\n              body: JSON.stringify({\n                contents: contents,\n                generationConfig: {\n                  temperature: 0.7,\n                  topK: 40,\n                  topP: 0.95,\n                  maxOutputTokens: 800,\n                },\n                safetySettings: [\n              {\n                category: \"HARM_CATEGORY_HARASSMENT\",\n                threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n              },\n              {\n                category: \"HARM_CATEGORY_HATE_SPEECH\",\n                threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n              },\n              {\n                category: \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n                threshold: \"BLOCK_ONLY_HIGH\"\n              },\n              {\n                category: \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n                threshold: \"BLOCK_MEDIUM_AND_ABOVE\"\n              }\n            ]\n          })\n            });\n\n            // Check HTTP status before trying to parse JSON\n            if (!response.ok) {\n              const errorText = await response.text();\n              console.error('API error response for roleplay:', errorText);\n              throw new Error(`API error in roleplay: ${response.status} - ${errorText || 'Unknown error'}`);\n            }\n\n            data = await response.json();\n            success = true;\n            \n          } catch (err) {\n            console.error(`Attempt ${4-retries} failed:`, err);\n            retries--;\n            \n            if (retries > 0) {\n              console.log(`Retrying in ${delay}ms...`);\n              await new Promise(resolve => setTimeout(resolve, delay));\n              delay *= 2; // Exponential backoff\n            } else {\n              throw err; // Re-throw the last error if all retries failed\n            }\n          }\n        }\n        \n        // Extract the model's response\n        if (data.candidates && data.candidates[0]?.content?.parts?.length > 0) {\n          const aiResponseText = data.candidates[0].content.parts[0].text;\n          \n          // Add AI response to history\n          this.history.push({\n            role: 'model',\n            parts: [{ text: aiResponseText }]\n          });\n          \n          return aiResponseText;\n        } else {\n          console.error('Unexpected roleplay API response structure:', data);\n          throw new Error('Invalid response format from Gemini API in roleplay');\n        }\n      } catch (fetchError) {\n        console.error('Fetch error in roleplay:', fetchError);\n        throw fetchError;\n      }\n    } catch (error) {\n      console.error('Error calling Gemini API:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Create the detailed system context from character and scenario\n   * @private\n   * @returns {string} - Formatted system context\n   */\n  _createSystemContext() {\n    const { name, age, physicalDescription, background, personality } = this.characterProfile;\n    const { title, setting, initialSituation, otherCharacters, toneAndThemes } = this.scenarioDetails;\n\n    // Create detailed system prompt\n    return `\nYou are roleplaying in a scenario titled \"${title}\".\n\n## My Character\nName: ${name || 'Unnamed'}\nAge: ${age || 'Unknown'}\nPhysical Description: ${physicalDescription || 'Not provided'}\nBackground: ${background || 'Not provided'}\nPersonality: ${personality || 'Not provided'}\n\n## Scenario Setting\nLocation: ${setting?.location || 'Unspecified'}\nTime: ${setting?.time || 'Unspecified'}\nAtmosphere: ${setting?.atmosphere || 'Unspecified'}\n\n## Initial Situation\n${initialSituation || 'No initial situation provided.'}\n\n## Other Characters\n${otherCharacters?.map(char => `\n- ${char.name} (${char.role}): ${char.description}\n  Relationship to protagonist: ${char.relationship}\n`).join('') || 'No other characters specified.'}\n\n## Tone and Themes\n${toneAndThemes || 'No specific tone or themes specified.'}\n\n## Roleplay Instructions:\n1. You are roleplaying as the characters in this scenario EXCEPT the protagonist.\n2. Stay in character at all times and maintain a realistic, consistent tone.\n3. Respond to the protagonist's actions, dialogue, and thoughts appropriately.\n4. Ensure your responses reflect the emotional atmosphere of the scene.\n5. When the protagonist communicates, they may mark their message as [DIALOGUE], [ACTION], or [THOUGHT].\n6. Format your responses to clearly indicate dialogue, actions, and narrative elements.\n7. Help develop the story in the direction indicated by the protagonist's choices.\n8. Keep responses rich and immersive, but reasonably concise (2-5 paragraphs).\n9. Be creative, emotionally resonant, and authentic to the established characters and world.\n10. Never break character by discussing the nature of the roleplay itself.\n`;\n  }\n\n  /**\n   * Save the current chat history\n   * @returns {Array} - The current chat history\n   */\n  exportChatHistory() {\n    return [...this.history];\n  }\n\n  /**\n   * Import an existing chat history\n   * @param {Array} history - Previous chat history\n   */\n  importChatHistory(history) {\n    this.history = [...history];\n  }\n}\n\nexport default GeminiService;"],"mappings":"AAAA;AACA;AACA;AACA,MAAMA,aAAa,CAAC;EAClBC,WAAWA,CAACC,MAAM,EAAE;IAClB,IAAI,CAACA,MAAM,GAAGA,MAAM;IACpB;IACA,IAAI,CAACC,OAAO,GAAG,wFAAwF;IACvG,IAAI,CAACC,OAAO,GAAG,EAAE;IACjB,IAAI,CAACC,gBAAgB,GAAG,IAAI;IAC5B,IAAI,CAACC,eAAe,GAAG,IAAI;EAC7B;;EAEA;AACF;AACA;AACA;AACA;EACEC,UAAUA,CAACF,gBAAgB,EAAEC,eAAe,EAAE;IAC5C,IAAI,CAACD,gBAAgB,GAAGA,gBAAgB;IACxC,IAAI,CAACC,eAAe,GAAGA,eAAe;IACtC,IAAI,CAACF,OAAO,GAAG,EAAE;;IAEjB;IACA,MAAMI,aAAa,GAAG,IAAI,CAACC,oBAAoB,CAAC,CAAC;IACjD,IAAI,CAACL,OAAO,CAACM,IAAI,CAAC;MAChBC,IAAI,EAAE,OAAO;MACbC,KAAK,EAAE,CAAC;QAAEC,IAAI,EAAEL;MAAc,CAAC;IACjC,CAAC,CAAC;;IAEF;IACA,IAAIF,eAAe,CAACQ,oBAAoB,EAAE;MACxC,IAAI,CAACV,OAAO,CAACM,IAAI,CAAC;QAChBC,IAAI,EAAE,OAAO;QACbC,KAAK,EAAE,CAAC;UAAEC,IAAI,EAAE,6BAA6BP,eAAe,CAACQ,oBAAoB;QAAG,CAAC;MACvF,CAAC,CAAC;IACJ;EACF;;EAEA;AACF;AACA;AACA;EACEC,kBAAkBA,CAACC,YAAY,EAAE;IAC/B;IACA,MAAMC,wBAAwB,GAAG,IAAI,CAACb,OAAO,CAACc,SAAS,CAACC,GAAG;MAAA,IAAAC,WAAA,EAAAC,gBAAA;MAAA,OACzDF,GAAG,CAACR,IAAI,KAAK,OAAO,MAAAS,WAAA,GACpBD,GAAG,CAACP,KAAK,CAAC,CAAC,CAAC,cAAAQ,WAAA,wBAAAC,gBAAA,GAAZD,WAAA,CAAcP,IAAI,cAAAQ,gBAAA,uBAAlBA,gBAAA,CAAoBC,QAAQ,CAAC,wBAAwB,CAAC;IAAA,CACxD,CAAC;;IAED;IACA,MAAMC,kBAAkB,GAAG;MACzBZ,IAAI,EAAE,OAAO;MACbC,KAAK,EAAE,CAAC;QAAEC,IAAI,EAAE,6BAA6BG,YAAY;MAAG,CAAC;IAC/D,CAAC;IAED,IAAIC,wBAAwB,KAAK,CAAC,CAAC,EAAE;MACnC;MACA,IAAI,CAACb,OAAO,CAACa,wBAAwB,CAAC,GAAGM,kBAAkB;IAC7D,CAAC,MAAM;MACL;MACA,IAAI,CAACnB,OAAO,CAACoB,MAAM,CAAC,CAAC,EAAE,CAAC,EAAED,kBAAkB,CAAC;IAC/C;;IAEA;IACA,IAAI,CAACnB,OAAO,CAACM,IAAI,CAAC;MAChBC,IAAI,EAAE,OAAO;MACbC,KAAK,EAAE,CAAC;QAAEC,IAAI,EAAE;MAA6H,CAAC;IAChJ,CAAC,CAAC;EACJ;;EAEA;AACF;AACA;AACA;AACA;EACE,MAAMY,eAAeA,CAACC,MAAM,EAAE;IAC5B,IAAI;MACFC,OAAO,CAACC,GAAG,CAAC,+BAA+B,CAAC;MAC5CD,OAAO,CAACC,GAAG,CAAC,gBAAgB,EAAE,IAAI,CAACzB,OAAO,CAAC;MAE3C,IAAI;QAAA,IAAA0B,iBAAA,EAAAC,qBAAA,EAAAC,sBAAA;QACF;QACA,IAAIC,OAAO,GAAG,CAAC;QACf,IAAIC,KAAK,GAAG,IAAI,CAAC,CAAC;QAClB,IAAIC,OAAO,GAAG,KAAK;QACnB,IAAIC,IAAI;QAER,OAAOH,OAAO,GAAG,CAAC,IAAI,CAACE,OAAO,EAAE;UAC9B,IAAI;YACF,MAAME,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAG,IAAI,CAAClC,OAAO,QAAQ,IAAI,CAACD,MAAM,EAAE,EAAE;cACjEoC,MAAM,EAAE,MAAM;cACdC,OAAO,EAAE;gBACP,cAAc,EAAE;cAClB,CAAC;cACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;gBACnBC,QAAQ,EAAE,CAAC;kBACThC,IAAI,EAAE,MAAM;kBACZC,KAAK,EAAE,CAAC;oBAAEC,IAAI,EAAEa;kBAAO,CAAC;gBAC1B,CAAC,CAAC;gBACFkB,gBAAgB,EAAE;kBAChBC,WAAW,EAAE,GAAG;kBAChBC,IAAI,EAAE,EAAE;kBACRC,IAAI,EAAE,IAAI;kBACVC,eAAe,EAAE;gBACnB;cACF,CAAC;YACH,CAAC,CAAC;;YAEF;YACA,IAAI,CAACZ,QAAQ,CAACa,EAAE,EAAE;cAChB,MAAMC,SAAS,GAAG,MAAMd,QAAQ,CAACvB,IAAI,CAAC,CAAC;cACvCc,OAAO,CAACwB,KAAK,CAAC,qBAAqB,EAAED,SAAS,CAAC;cAC/C,MAAM,IAAIE,KAAK,CAAC,cAAchB,QAAQ,CAACiB,MAAM,MAAMH,SAAS,IAAI,eAAe,EAAE,CAAC;YACpF;YAEAf,IAAI,GAAG,MAAMC,QAAQ,CAACkB,IAAI,CAAC,CAAC;YAC5B3B,OAAO,CAACC,GAAG,CAAC,yBAAyB,EAAEa,IAAI,CAACC,SAAS,CAACP,IAAI,EAAE,IAAI,EAAE,CAAC,CAAC,CAACoB,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,KAAK,CAAC;YAC/FrB,OAAO,GAAG,IAAI;UAChB,CAAC,CAAC,OAAOsB,GAAG,EAAE;YACZ7B,OAAO,CAACwB,KAAK,CAAC,WAAW,CAAC,GAACnB,OAAO,UAAU,EAAEwB,GAAG,CAAC;YAClDxB,OAAO,EAAE;YAET,IAAIA,OAAO,GAAG,CAAC,EAAE;cACfL,OAAO,CAACC,GAAG,CAAC,eAAeK,KAAK,OAAO,CAAC;cACxC,MAAM,IAAIwB,OAAO,CAACC,OAAO,IAAIC,UAAU,CAACD,OAAO,EAAEzB,KAAK,CAAC,CAAC;cACxDA,KAAK,IAAI,CAAC,CAAC,CAAC;YACd,CAAC,MAAM;cACL,MAAMuB,GAAG,CAAC,CAAC;YACb;UACF;QACF;;QAEA;QACA,IAAIrB,IAAI,CAACyB,UAAU,IAAI,EAAA/B,iBAAA,GAAAM,IAAI,CAACyB,UAAU,CAAC,CAAC,CAAC,cAAA/B,iBAAA,wBAAAC,qBAAA,GAAlBD,iBAAA,CAAoBgC,OAAO,cAAA/B,qBAAA,wBAAAC,sBAAA,GAA3BD,qBAAA,CAA6BlB,KAAK,cAAAmB,sBAAA,uBAAlCA,sBAAA,CAAoC+B,MAAM,IAAG,CAAC,EAAE;UACrE,OAAO3B,IAAI,CAACyB,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAACjD,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI;QACjD,CAAC,MAAM;UACLc,OAAO,CAACwB,KAAK,CAAC,oCAAoC,EAAEhB,IAAI,CAAC;UACzD,MAAM,IAAIiB,KAAK,CAAC,yCAAyC,CAAC;QAC5D;MACF,CAAC,CAAC,OAAOW,UAAU,EAAE;QACnBpC,OAAO,CAACwB,KAAK,CAAC,cAAc,EAAEY,UAAU,CAAC;QACzC,MAAMA,UAAU;MAClB;IACF,CAAC,CAAC,OAAOZ,KAAK,EAAE;MACdxB,OAAO,CAACwB,KAAK,CAAC,2BAA2B,EAAEA,KAAK,CAAC;MACjD,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,MAAMa,gBAAgBA,CAACC,WAAW,EAAEC,WAAW,EAAE;IAC/C,IAAI;MACF;MACA,IAAI,CAAC9D,OAAO,CAACM,IAAI,CAAC;QAChBC,IAAI,EAAE,MAAM;QACZC,KAAK,EAAE,CAAC;UAAEC,IAAI,EAAE,IAAIqD,WAAW,CAACC,WAAW,CAAC,CAAC,KAAKF,WAAW;QAAG,CAAC;MACnE,CAAC,CAAC;;MAEF;MACA,MAAMtB,QAAQ,GAAG,CAAC,GAAG,IAAI,CAACvC,OAAO,CAAC;MAElCuB,OAAO,CAACC,GAAG,CAAC,wCAAwC,CAAC;MACrDD,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAE,IAAI,CAACzB,OAAO,CAAC;MAE7C,IAAI;QAAA,IAAAiE,kBAAA,EAAAC,qBAAA,EAAAC,sBAAA;QACF;QACA,IAAItC,OAAO,GAAG,CAAC;QACf,IAAIC,KAAK,GAAG,IAAI,CAAC,CAAC;QAClB,IAAIC,OAAO,GAAG,KAAK;QACnB,IAAIC,IAAI;QAER,OAAOH,OAAO,GAAG,CAAC,IAAI,CAACE,OAAO,EAAE;UAC9B,IAAI;YACF,MAAME,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAG,IAAI,CAAClC,OAAO,QAAQ,IAAI,CAACD,MAAM,EAAE,EAAE;cACjEoC,MAAM,EAAE,MAAM;cACdC,OAAO,EAAE;gBACP,cAAc,EAAE;cAClB,CAAC;cACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;gBACnBC,QAAQ,EAAEA,QAAQ;gBAClBC,gBAAgB,EAAE;kBAChBC,WAAW,EAAE,GAAG;kBAChBC,IAAI,EAAE,EAAE;kBACRC,IAAI,EAAE,IAAI;kBACVC,eAAe,EAAE;gBACnB,CAAC;gBACDuB,cAAc,EAAE,CAClB;kBACEC,QAAQ,EAAE,0BAA0B;kBACpCC,SAAS,EAAE;gBACb,CAAC,EACD;kBACED,QAAQ,EAAE,2BAA2B;kBACrCC,SAAS,EAAE;gBACb,CAAC,EACD;kBACED,QAAQ,EAAE,iCAAiC;kBAC3CC,SAAS,EAAE;gBACb,CAAC,EACD;kBACED,QAAQ,EAAE,iCAAiC;kBAC3CC,SAAS,EAAE;gBACb,CAAC;cAEL,CAAC;YACC,CAAC,CAAC;;YAEF;YACA,IAAI,CAACrC,QAAQ,CAACa,EAAE,EAAE;cAChB,MAAMC,SAAS,GAAG,MAAMd,QAAQ,CAACvB,IAAI,CAAC,CAAC;cACvCc,OAAO,CAACwB,KAAK,CAAC,kCAAkC,EAAED,SAAS,CAAC;cAC5D,MAAM,IAAIE,KAAK,CAAC,0BAA0BhB,QAAQ,CAACiB,MAAM,MAAMH,SAAS,IAAI,eAAe,EAAE,CAAC;YAChG;YAEAf,IAAI,GAAG,MAAMC,QAAQ,CAACkB,IAAI,CAAC,CAAC;YAC5BpB,OAAO,GAAG,IAAI;UAEhB,CAAC,CAAC,OAAOsB,GAAG,EAAE;YACZ7B,OAAO,CAACwB,KAAK,CAAC,WAAW,CAAC,GAACnB,OAAO,UAAU,EAAEwB,GAAG,CAAC;YAClDxB,OAAO,EAAE;YAET,IAAIA,OAAO,GAAG,CAAC,EAAE;cACfL,OAAO,CAACC,GAAG,CAAC,eAAeK,KAAK,OAAO,CAAC;cACxC,MAAM,IAAIwB,OAAO,CAACC,OAAO,IAAIC,UAAU,CAACD,OAAO,EAAEzB,KAAK,CAAC,CAAC;cACxDA,KAAK,IAAI,CAAC,CAAC,CAAC;YACd,CAAC,MAAM;cACL,MAAMuB,GAAG,CAAC,CAAC;YACb;UACF;QACF;;QAEA;QACA,IAAIrB,IAAI,CAACyB,UAAU,IAAI,EAAAQ,kBAAA,GAAAjC,IAAI,CAACyB,UAAU,CAAC,CAAC,CAAC,cAAAQ,kBAAA,wBAAAC,qBAAA,GAAlBD,kBAAA,CAAoBP,OAAO,cAAAQ,qBAAA,wBAAAC,sBAAA,GAA3BD,qBAAA,CAA6BzD,KAAK,cAAA0D,sBAAA,uBAAlCA,sBAAA,CAAoCR,MAAM,IAAG,CAAC,EAAE;UACrE,MAAMY,cAAc,GAAGvC,IAAI,CAACyB,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAACjD,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI;;UAE/D;UACA,IAAI,CAACT,OAAO,CAACM,IAAI,CAAC;YAChBC,IAAI,EAAE,OAAO;YACbC,KAAK,EAAE,CAAC;cAAEC,IAAI,EAAE6D;YAAe,CAAC;UAClC,CAAC,CAAC;UAEF,OAAOA,cAAc;QACvB,CAAC,MAAM;UACL/C,OAAO,CAACwB,KAAK,CAAC,6CAA6C,EAAEhB,IAAI,CAAC;UAClE,MAAM,IAAIiB,KAAK,CAAC,qDAAqD,CAAC;QACxE;MACF,CAAC,CAAC,OAAOW,UAAU,EAAE;QACnBpC,OAAO,CAACwB,KAAK,CAAC,0BAA0B,EAAEY,UAAU,CAAC;QACrD,MAAMA,UAAU;MAClB;IACF,CAAC,CAAC,OAAOZ,KAAK,EAAE;MACdxB,OAAO,CAACwB,KAAK,CAAC,2BAA2B,EAAEA,KAAK,CAAC;MACjD,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;EACE1C,oBAAoBA,CAAA,EAAG;IACrB,MAAM;MAAEkE,IAAI;MAAEC,GAAG;MAAEC,mBAAmB;MAAEC,UAAU;MAAEC;IAAY,CAAC,GAAG,IAAI,CAAC1E,gBAAgB;IACzF,MAAM;MAAE2E,KAAK;MAAEC,OAAO;MAAEC,gBAAgB;MAAEC,eAAe;MAAEC;IAAc,CAAC,GAAG,IAAI,CAAC9E,eAAe;;IAEjG;IACA,OAAO;AACX,4CAA4C0E,KAAK;AACjD;AACA;AACA,QAAQL,IAAI,IAAI,SAAS;AACzB,OAAOC,GAAG,IAAI,SAAS;AACvB,wBAAwBC,mBAAmB,IAAI,cAAc;AAC7D,cAAcC,UAAU,IAAI,cAAc;AAC1C,eAAeC,WAAW,IAAI,cAAc;AAC5C;AACA;AACA,YAAY,CAAAE,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEI,QAAQ,KAAI,aAAa;AAC9C,QAAQ,CAAAJ,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEK,IAAI,KAAI,aAAa;AACtC,cAAc,CAAAL,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEM,UAAU,KAAI,aAAa;AAClD;AACA;AACA,EAAEL,gBAAgB,IAAI,gCAAgC;AACtD;AACA;AACA,EAAE,CAAAC,eAAe,aAAfA,eAAe,uBAAfA,eAAe,CAAEK,GAAG,CAACC,IAAI,IAAI;AAC/B,IAAIA,IAAI,CAACd,IAAI,KAAKc,IAAI,CAAC9E,IAAI,MAAM8E,IAAI,CAACC,WAAW;AACjD,iCAAiCD,IAAI,CAACE,YAAY;AAClD,CAAC,CAAC,CAACC,IAAI,CAAC,EAAE,CAAC,KAAI,gCAAgC;AAC/C;AACA;AACA,EAAER,aAAa,IAAI,uCAAuC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;EACC;;EAEA;AACF;AACA;AACA;EACES,iBAAiBA,CAAA,EAAG;IAClB,OAAO,CAAC,GAAG,IAAI,CAACzF,OAAO,CAAC;EAC1B;;EAEA;AACF;AACA;AACA;EACE0F,iBAAiBA,CAAC1F,OAAO,EAAE;IACzB,IAAI,CAACA,OAAO,GAAG,CAAC,GAAGA,OAAO,CAAC;EAC7B;AACF;AAEA,eAAeJ,aAAa","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}